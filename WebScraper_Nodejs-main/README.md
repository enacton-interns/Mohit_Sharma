# ğŸ“š Web Scraper

A modular, configurable Node.js web scraper built to extract data from paginated websites like [Books to Scrape](https://books.toscrape.com). It features retry logic, JSON/CSV saving, notifications, and structured logging.

---

## ğŸš€ Features

- Scrape paginated product listings
- Save data in `.json`, `.csv`, or both
- Built-in retry with exponential backoff
- Configurable via `.env` file
- Notification system for status updates
- Structured logging for better debugging

---

## ğŸ§° Project Structure

```

src/
â”œâ”€â”€ config/ # Environment-based configuration
â”‚ â””â”€â”€ default.js
â”œâ”€â”€ scraper/ # Fetch and parse logic
â”‚ â”œâ”€â”€ fetcher.js
â”‚ â”œâ”€â”€ parser.js
â”‚ â””â”€â”€ pagination.js
â”œâ”€â”€ storage/ # Output handlers
â”‚ â”œâ”€â”€ csvWriter.js
â”‚ â””â”€â”€ jsonWriter.js
â”œâ”€â”€ services/ # Notifications
â”‚ â””â”€â”€ notification.js
â”œâ”€â”€ utils/ # Reusable utilities
â”‚ â”œâ”€â”€ errorHandler.js
â”‚ â””â”€â”€ logger.js
â”œâ”€â”€ index.js # Main entry point
â””â”€â”€ .env # Runtime configuration

```

---

## ğŸ“¦ Requirements

- Node.js v16+
- npm

---

## âš™ï¸ Configuration

Create a `.env` file in the `src/` directory:

```env
BASE_URL=https://books.toscrape.com
MAX_PAGES=3
PAGE_PARAM=catalogue/page-
RETRY_COUNT=3
RETRY_DELAY=1000
TIMEOUT=5000
SAVE_FORMAT=both
NOTIFICATIONS_ENABLED=true
```
